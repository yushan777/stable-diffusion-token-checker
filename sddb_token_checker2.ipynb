{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Stable Diffusion Dreambooth Token Checker\n",
    "\n",
    "This notebook provides an improved interface for checking how Stable Diffusion tokens are interpreted and generated. Key features:\n",
    "\n",
    "* Better organized code structure\n",
    "* Improved error handling and logging\n",
    "* More efficient image generation\n",
    "* Interactive widgets for all settings\n",
    "* Better progress tracking\n",
    "* Improved visualization of token breakdown\n",
    "\n",
    "First, let's install our requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "setup_requirements"
   },
   "outputs": [],
   "source": [
    "#@title 1. Install Requirements\n",
    "print(\"Installing requirements...\")\n",
    "!pip install -q --upgrade diffusers[torch] transformers xformers triton ipywidgets\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import logging
    "from IPython.display import clear_output, display\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Download font if needed\n",
    "if not os.path.exists('inconsolata.regular.ttf'):\n",
    "    !wget 'https://github.com/yushan777/stable-diffusion-token-checker/raw/main/inconsolata.regular.ttf'\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 2. Initialize Model Pipeline\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, AutoencoderKL, DDIMScheduler\n",
    "from transformers import CLIPTokenizer\n",
    "\n",
    "MODEL_CHOICES = {\n",
    "    'Stable Diffusion 1.5': \"runwayml/stable-diffusion-v1-5\",\n",
    "    'Stable Diffusion 2.1': \"stabilityai/stable-diffusion-2-1\"\n",
    "}\n",
    "\n",
    "SELECT_MODEL = 'Stable Diffusion 1.5' #@param [\"Stable Diffusion 1.5\", \"Stable Diffusion 2.1\"]\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_path: str\n",
    "    vae_path: Optional[str] = None\n",
    "\n",
    "def setup_pipeline(config: ModelConfig):\n",
    "    logger.info(f\"Loading model: {config.model_path}\")\n",
    "    \n",
    "    # Clear CUDA cache if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipe_kwargs = {\n",
    "        \"variant\": \"fp16\",\n",
    "        \"torch_dtype\": torch.float16\n",
    "    }\n",
    "    \n",
    "    if config.vae_path:\n",
    "        pipe_kwargs[\"vae\"] = AutoencoderKL.from_pretrained(\n",
    "            config.vae_path,\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "    \n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        config.model_path,\n",
    "        **pipe_kwargs\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    \n    return pipe\n",
    "\n",
    "# Setup model configuration\n",
    "model_config = ModelConfig(\n",
    "    model_path=MODEL_CHOICES[SELECT_MODEL],\n",
    "    vae_path=\"stabilityai/sd-vae-ft-mse\" if SELECT_MODEL == 'Stable Diffusion 1.5' else None\n",
    ")\n",
    "\n",
    "# Initialize pipeline\n",
    "pipe = setup_pipeline(model_config)\n",
    "\n",
    "print(\"✅ Model pipeline initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 3. Token Analysis Functions\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class TokenAnalysisConfig:\n",
    "    image_size: int = 512\n",
    "    grid_size: Tuple[int, int] = (3, 3)\n",
    "    font_size: int = 35\n",
    "    line_padding: int = 5\n",
    "\n",
    "class TokenAnalyzer:\n",
    "    def __init__(self, model_path: str, config: TokenAnalysisConfig):\n",
    "        self.config = config\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(model_path, subfolder=\"tokenizer\")\n",
    "        self.font = ImageFont.truetype(\"inconsolata.regular.ttf\", size=config.font_size)\n",
    "        self._load_vocabulary(model_path)\n",
    "\n",
    "    def _load_vocabulary(self, model_path: str):\n",
    "        vocab_path = None\n",
    "        for root, _, files in os.walk(self.tokenizer.cache_dir):\n",
    "            if \"vocab.json\" in files:\n",
    "                vocab_path = Path(root) / \"vocab.json\"\n",
    "                break\n",
    "        \n",
    "        if vocab_path is None:\n",
    "            raise FileNotFoundError(\"Could not find vocab.json\")\n",
    "            \n",
    "        with open(vocab_path, \"r\", encoding='utf-8') as f:\n",
    "            self.vocab = {v: k for k, v in json.load(f).items()}\n",
    "\n",
    "    def analyze_token(self, token: str) -> Tuple[List[str], int]:\n",
    "        \"\"\"Analyze a token and return its breakdown and count.\"\"\"\n",
    "        inputs = self.tokenizer(token, padding=True)\n",
    "        token_data = []\n",
    "        current_line = \"\"\n",
    "        token_count = 0\n",
    "        \n",
    "        # Process each token\n",
    "        for token_id in inputs[\"input_ids\"]:\n",
    "            if token_id not in [49406, 49407]:  # Skip start/end tokens\n",
    "                token_text = self.vocab[token_id]\n",
    "                token_count += 1\n",
    "                \n",
    "                new_text = f\"[{token_text}] \"\n",
    "                text_width = self.font.getlength(current_line + new_text)\n",
    "                \n",
    "                if text_width >= (self.config.image_size * self.config.grid_size[0] - 256):\n",
    "                    token_data.append(current_line.strip())\n",
    "                    current_line = new_text\n",
    "                else:\n",
    "                    current_line += new_text\n",
    "        \n",
    "        if current_line:\n",
    "            token_data.append(current_line.strip())\n",
    "            \n",
    "        return token_data, token_count\n",
    "\n",
    "# Initialize analyzer\n",
    "token_analyzer = TokenAnalyzer(\n",
    "    model_path=model_config.model_path,\n",
    "    config=TokenAnalysisConfig()\n",
    ")\n",
    "\n",
    "print(\"✅ Token analysis functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 4. Configure Tokens and Classes\n",
    "\n",
    "TOKENS = \"\" #@param {type:\"string\"}\n",
    "#@markdown Enter tokens separated by commas\n",
    "\n",
    "#@markdown ### Class Options\n",
    "class_person = False #@param {type:\"boolean\"}\n",
    "class_man = False #@param {type:\"boolean\"}\n",
    "class_woman = False #@param {type:\"boolean\"}\n",
    "class_artstyle = False #@param {type:\"boolean\"}\n",
    "class_other = \"\" #@param {type:\"string\"}\n",
    "\n",
    "def parse_tokens(token_string: str) -> List[str]:\n",
    "    \"\"\"Parse token string into list of tokens.\"\"\"\n",
    "    if ',' in token_string:\n",
    "        tokens = [t.strip() for t in token_string.split(',')]\n",
    "    else:\n",
    "        tokens = [t.strip() for t in token_string.split()]\n",
    "    return [t for t in tokens if t]  # Remove empty strings\n",
    "\n",
    "def get_class_combinations(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"Generate all token + class combinations.\"\"\"\n",
    "    result = tokens.copy()\n",
    "    class_words = []\n",
    "    \n",
    "    if class_person:\n",
    "        class_words.append(\"person\")\n",
    "    if class_man:\n",
    "        class_words.append(\"man\")\n",
    "    if class_woman:\n",
    "        class_words.append(\"woman\")\n",
    "    if class_artstyle:\n",
    "        class_words.append(\"artstyle\")\n",
    "    if class_other:\n",
    "        class_words.extend(parse_tokens(class_other))\n",
    "    \n",
    "    for token in tokens:\n",
    "        for class_word in class_words:\n",
    "            result.append(f\"{token} {class_word}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Parse tokens and generate combinations\n",
    "base_tokens = parse_tokens(TOKENS)\n",
    "all_tokens = get_class_combinations(base_tokens)\n",
    "\n",
    "print(\"Tokens to process:\")\n",
    "for token in all_tokens:\n",
    "    print(f\"- {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title 5. Generate Images\n",
    "\n",
    "seed = -1 #@param {type:\"number\"}\n",
    "steps = 20 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "preview_scale = 0.5 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
    "\n",
    "@dataclass\n",
    "class GenerationConfig:\n",
    "    seed: int\n",
    "    steps: int\n",
    "    preview_scale: float\n",
    "    grid_size: Tuple[int, int] = (3, 3)\n",
    "    image_size: int = 512\n",
    "\n",
    "def generate_image_grid(token: str, config: GenerationConfig):\n",
    "    \"\"\"Generate grid of images for a token.\"\"\"\n",
    "    # Analyze token\n",
    "    token_data, token_count = token_analyzer.analyze_token(token)\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    grid_width = config.image_size * config.grid_size[0]\n",
    "    text_height = token_analyzer.font.getsize(\"Test\")[1] + 5\n",
    "    title_height = text_height * (len(token_data) + 2)\n",
    "    grid_height = (config.image_size * config.grid_size[1]) + title_height\n",
    "    \n",
    "    # Create grid image\n",
    "    grid = Image.new('RGB', (grid_width, grid_height), 'black')\n",
    "    \n",
    "    # Generate images\n",
    "    generator = torch.Generator(device=\"cuda\")\n",
    "    total_images = config.grid_size[0] * config.grid_size[1]\n",
    "    \n",
    "    for i in range(total_images):\n",
    "        current_seed = generator.seed() if config.seed == -1 else config.seed + i\n",
    "        generator.manual_seed(current_seed)\n",
    "        \n",
    "        print(f\"Generating image {i+1}/{total_images} (seed: {current_seed})\")\n",
    "        \n",
    "        with torch.autocast(\"cuda\"),