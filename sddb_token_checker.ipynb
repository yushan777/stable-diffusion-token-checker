{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nGjMsHOZIP"
      },
      "source": [
        "# Stable Diffusion Dreambooth Token Checker\n",
        "\n",
        "Adapted from scripts and ideas by 2kpr\n",
        "\n",
        "https://www.reddit.com/r/StableDiffusion/comments/zc65l4/rare_tokens_for_dreambooth_training_stable/<br>\n",
        "https://github.com/2kpr/dreambooth-tokens<br>\n",
        "https://arxiv.org/pdf/2208.12242<br><br>\n",
        "Join The [Stable Diffusion Dreambooth Discord Server](https://discord.gg/wNNs2JNF7G)<br>\n",
        "Medium Article : [Good Token, Bad Token](https://medium.com/@yushantripleseven/good-token-bad-token-1d66891b0b0a)</br>\n",
        "\n",
        "**Purpose:** To check what a given token / token+class pair might generate from the model you are planning to train on. It will also show a breakdown of how your token is tokenized into subwords. So that long, convoluted token you came up with might actually be broken up into subtokens which are very common words themselves and so having a very strong prior association in the model.\n",
        "\n",
        "There is no rule to say you can't just use someone's regular name. You can use `tomcruise` if you want but you'll just end up pulling weights associated with him to the subject you are training and erasing old tomcruise from the model's memory. \n",
        "\n",
        "A 3x3 grid of images will be generated from prompts using token(s) you specify.  You can also include class words so that each token will be paired with the selected class(es) which will also be added to the list.\n",
        "\n",
        "### What to look for:\n",
        "\n",
        "* If outputs show a consistent theme, then the token you are using probably already has strong associations in the model. (not ideal)\n",
        "* If outputs appear random then it will probably have weaker associations in the model. (better)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ku2PLmLxMreH"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Requirements\n",
        "\n",
        "print(\"This will take a couple of minutes...\")\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "!pip install -q xformers==0.0.16\n",
        "!pip install -q transformers\n",
        "!pip install -q triton\n",
        "\n",
        "# =========================================================================================\n",
        "# Get Font\n",
        "# =========================================================================================\n",
        "import os\n",
        "from os.path import exists\n",
        "if exists('inconsolata.regular.ttf')==False: \n",
        "  !wget 'https://github.com/yushan777/stable-diffusion-token-checker/raw/main/inconsolata.regular.ttf'\n",
        "\n",
        "# =========================================================================================\n",
        "# Image Output dir\n",
        "# =========================================================================================\n",
        "OUTPUT_DIR = \"output\"\n",
        "if exists(OUTPUT_DIR)==False:\n",
        "    os.mkdir(OUTPUT_DIR)\n",
        "\n",
        "import shutil\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"Finished installing requirements.\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K-akUTZHw7Ls"
      },
      "outputs": [],
      "source": [
        "#@title 2. Setup Functions\n",
        "\n",
        "# ======================================================================================\n",
        "# DEFINE FUNCTIONS \n",
        "# ======================================================================================\n",
        "\n",
        "#@title 2. Define Functions\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from transformers import CLIPTokenizer, CLIPModel\n",
        "import json\n",
        "\n",
        "split_positions = []\n",
        "image_width_height = 512\n",
        "grid_rows = 3\n",
        "grid_cols = 3\n",
        "grid_width = image_width_height * grid_cols\n",
        "myFont = ImageFont.truetype(\"inconsolata.regular.ttf\", size=35)\n",
        "\n",
        "# ===========================================================================\n",
        "# ===========================================================================\n",
        "def tokenize(token):\n",
        "\n",
        "  with open(Vocab_File_Path, \"r\", encoding='utf-8') as f:\n",
        "    vocab = json.load(f)\n",
        "    vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "  tokenizer = CLIPTokenizer.from_pretrained(MODEL_PATH, subfolder=\"tokenizer\",revision=\"fp16\")\n",
        "\n",
        "  #inputs = tokenizer(sys.argv[1], padding=True)\n",
        "  inputs = tokenizer(f'{token}', padding=True)\n",
        "  value = sum(inputs[\"input_ids\"])\n",
        "  value_str = str(value)\n",
        "  token_data = ''\n",
        "\n",
        "  # holds lines of sub-tokens up to the width of the grid (minus margin)\n",
        "  return_list = []\n",
        "  margin_right = 256\n",
        "\n",
        "  # add current string to list\n",
        "  #return_list.append(token_data)\n",
        "  #token_data = '' # reset\n",
        "\n",
        "  \n",
        "  token_count = 0\n",
        "  for x in range(len(inputs[\"input_ids\"])):\n",
        "    #print(vocab[inputs[\"input_ids\"][x]] + \" \" + str(inputs[\"input_ids\"][x]))\n",
        "      \n",
        "    # don't include <|startoftext|> 49406 or <|endoftext|> 49407\n",
        "    if inputs[\"input_ids\"][x] != 49406 and inputs[\"input_ids\"][x] != 49407:\n",
        "      # add next sub-token\n",
        "      token_data += '[' + vocab[inputs[\"input_ids\"][x]] + ']'\n",
        "      token_count += 1 \n",
        "      # check string length, if >= grid_width     \n",
        "      if (get_text_size(token_data, myFont)[0] + margin_right) >= grid_width:\n",
        "        return_list.append(token_data.strip())\n",
        "        token_data = '' #reset string\n",
        "      if x < len(inputs[\"input_ids\"]) - 2:\n",
        "        token_data += ' '\n",
        "    \n",
        "  # add last or only string\n",
        "  if len(token_data.strip()) > 0:\n",
        "    return_list.append(token_data.strip())\n",
        "\n",
        "  print(return_list)\n",
        "  print(\"Token Count = \" + f'{token_count}')\n",
        "  \n",
        "\n",
        "  return return_list, token_count\n",
        "\n",
        "# ===========================================================================\n",
        "# ===========================================================================\n",
        "def generate_grid(seed, steps, preview_scale):\n",
        "\n",
        "  if steps == 0: steps = 20\n",
        "\n",
        "  # read word list from file\n",
        "  #with open(\"4tokens_short.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  #\ttokenList = [line.strip() for line in f.readlines()]\n",
        "\n",
        "  # =============================================================\n",
        "  print(\"start\")\n",
        "    \n",
        "  text_height = get_text_size('hello', myFont)[1] # get height of text for this font - string is not important\n",
        "  titlebar_height = 64\n",
        "  line_padding = 5\n",
        "  text_height += line_padding\n",
        "\n",
        "  # for each token...\n",
        "  for token in token_list:\n",
        "\n",
        "    token_data = tokenize(token)\n",
        "    token_data_lines = token_data[0]\n",
        "    token_count = token_data[1]\n",
        "    \n",
        "    titlebar_height = text_height * (len(token_data_lines)+2) #+2 for the Token and Token Count lines\n",
        "    titlebar_height += line_padding * 2 # add extra padding so it's not too tight\n",
        "\n",
        "    # set generator\n",
        "    generator_cuda = torch.Generator(device=\"cuda\")\n",
        "    \n",
        "    # init grid image obj. \n",
        "    grid = Image.new('RGB', size=(grid_cols*image_width_height, (grid_rows*image_width_height)+titlebar_height))\n",
        "\n",
        "    seed_list = [] #\n",
        "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
        "      for i in range(9):\n",
        "        if seed == -1: # random seed\n",
        "          current_seed = generator_cuda.seed()          \n",
        "        else: # fixed seed : add loop counter\n",
        "          current_seed = seed + i\n",
        "          generator_cuda.manual_seed(current_seed)  \n",
        "\n",
        "        seed_list.append(current_seed) # add to list        \n",
        "        print(f'seed : {current_seed}')\n",
        "\n",
        "        image = pipe(token, generator=generator_cuda, num_inference_steps=steps, num_images_per_prompt=1).images[0]\n",
        "        grid.paste(image, box=(i%grid_cols*image_width_height, (i//grid_cols*512)+titlebar_height))\n",
        "\n",
        "    # Call draw Method \n",
        "    draw = ImageDraw.Draw(grid)\n",
        "  \n",
        "    # Add Text to grid\n",
        "    x = 10\n",
        "    y = 0\n",
        "    draw.text((x, y), f'Token: {token}', font=myFont, fill=(255, 255, 255))\n",
        "    y += text_height\n",
        "    draw.text((x, y), f'Token Count = {token_count}', font=myFont, fill=(255, 255, 255))\n",
        "    y += text_height\n",
        "    for line in token_data_lines:\n",
        "      draw.text((x, y), line, font=myFont, fill=(255, 255, 255))\n",
        "      y += text_height\n",
        "\n",
        "    # since quality is not a priority we will save in jpg with some compression\n",
        "    # to keep filesizes small and faster loading. \n",
        "    filename = token\n",
        "    if token ==' ' or token == '':\n",
        "      filename = 'empty'    \n",
        "\n",
        "    grid.save(OUTPUT_DIR + \"/\" + filename + \".jpg\", optimize=True, quality=60)\n",
        "\n",
        "    #image = Image.open(f'{grid}')\n",
        "    display(grid.resize(( int(grid.width * preview_scale), int(grid.height * preview_scale))))\n",
        "    \n",
        "# ===========================================================================\n",
        "# ===========================================================================\n",
        "def get_text_size(text_string, font):\n",
        "  # https://stackoverflow.com/a/46220683/9263761\n",
        "  ascent, descent = font.getmetrics()\n",
        "  text_width = font.getmask(text_string).getbbox()[2]\n",
        "  text_height = font.getmask(text_string).getbbox()[3] + descent\n",
        "  #print(\"text length = \" + str(text_width) )\n",
        "  return (text_width, text_height)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Select Model\n",
        "# =========================================================================================\n",
        "# SETUP SD PIPELINE\n",
        "# =========================================================================================\n",
        "import torch\n",
        "import xformers\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL, DDIMScheduler\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "SELECT_MODEL = 'Stable Diffusion 1.5' #@param [\"Stable Diffusion 1.5\", \"Stable Diffusion 2.1\"]\n",
        "\n",
        "# can be local paths also\n",
        "if SELECT_MODEL=='Stable Diffusion 1.5':\n",
        "  MODEL_PATH = \"runwayml/stable-diffusion-v1-5\"\n",
        "  VAE_PATH = \"stabilityai/sd-vae-ft-mse\"\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(f'{MODEL_PATH}', \n",
        "                                               vae = AutoencoderKL.from_pretrained(f'{VAE_PATH}', torch_dtype = torch.float16), \n",
        "                                               revision=\"fp16\", \n",
        "                                               torch_dtype = torch.float16, \n",
        "                                               safety_checker = None)\n",
        "elif SELECT_MODEL=='Stable Diffusion 2.1':\n",
        "  MODEL_PATH = \"stabilityai/stable-diffusion-2-1\"\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(f'{MODEL_PATH}',                                                \n",
        "                                               revision=\"fp16\", \n",
        "                                               torch_dtype = torch.float16, \n",
        "                                               safety_checker = None)\n",
        "\n",
        "\n",
        "\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# =========================================================================================\n",
        "# Copy the vocab.json from the cache to current dir\n",
        "# =========================================================================================\n",
        "# tokenizer/vocab.json files are normally saved in cache e.g.\n",
        "# /root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/xxxxx/tokenizer/vocab.json\n",
        "\n",
        "name = 'vocab.json' \n",
        "init_path = '/root/.cache/'\n",
        "result = []\n",
        "for root, dirs, files in os.walk(init_path):\n",
        "  if name in files:\n",
        "    result.append(os.path.join(root, name))\n",
        "\n",
        "for cached_vocab_path in result:\n",
        "  print('-> ' + cached_vocab_path)\n",
        "\n",
        "  #split the cached dir path\n",
        "  dirs_list = cached_vocab_path.split('/')\n",
        "  # get repo name without username\n",
        "  HF_repo_name = MODEL_PATH.split('/')\n",
        "\n",
        "  #build dir path to copy vocab to\n",
        "  copy_to_dir = 'dictionary/' + HF_repo_name[1] + '/' + dirs_list[8] + '/' + dirs_list[9]\n",
        "\n",
        "  # create target dir if not exist\n",
        "  os.makedirs(os.path.dirname(copy_to_dir), exist_ok=True)\n",
        "  #copy\n",
        "  shutil.copy(cached_vocab_path, copy_to_dir)\n",
        "  \n",
        "  #Set var\n",
        "  Vocab_File_Path = copy_to_dir\n",
        "\n",
        "print(\"Finished.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNmNk5QTD0Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rrQr2_5xD9DH"
      },
      "outputs": [],
      "source": [
        "#@title 4. Token / Class Words\n",
        "#@markdown add your token words you would like to test (comma separated)\n",
        "TOKENS = \"sks, johndoe\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "delimeter = ''\n",
        "if ',' in TOKENS:\n",
        "    delimeter = ','\n",
        "else:\n",
        "    delimeter = ' ' #this will also clear empty strings\n",
        "    \n",
        "# split and remove any whitespaces\n",
        "token_list = [x.strip() for x in TOKENS.split(delimeter)]\n",
        "\n",
        "#for t in token_list:\n",
        "# print(t)\n",
        "\n",
        "#@markdown ___ \n",
        "\n",
        "#@markdown (Optional) add class to the list?\n",
        "\n",
        "class_person = True #@param {type:\"boolean\"}\n",
        "class_man = False #@param {type:\"boolean\"}\n",
        "class_woman = False #@param {type:\"boolean\"}\n",
        "class_artstyle = False #@param {type:\"boolean\"}\n",
        "class_other = \"\" #@param {type:\"string\"}\n",
        "\n",
        "token_and_person_list = []\n",
        "token_and_man_list = []\n",
        "token_and_woman_list = []\n",
        "token_and_artstyle_list = []\n",
        "token_and_other_list = []\n",
        "# =============================================\n",
        "if class_person==True:\n",
        "  for t in token_list:\n",
        "    token_and_person_list.append(f'{t} person')\n",
        "\n",
        "# =============================================\n",
        "if class_man==True:\n",
        "  for t in token_list:\n",
        "    token_and_man_list.append(f'{t} man')\n",
        "\n",
        "# =============================================\n",
        "if class_woman==True:\n",
        "  for t in token_list:\n",
        "    token_and_woman_list.append(f'{t} woman')\n",
        "\n",
        "# =============================================\n",
        "if class_artstyle==True:\n",
        "  for t in token_list:\n",
        "    token_and_artstyle_list.append(f'{t} artstyle')\n",
        "\n",
        "# =============================================\n",
        "if len(class_other) > 0 :\n",
        "  for t in token_list:\n",
        "    token_and_other_list.append(f'{t} {class_other}')\n",
        "\n",
        "# add token+class to original list\n",
        "token_list.extend(token_and_person_list)\n",
        "token_list.extend(token_and_man_list)\n",
        "token_list.extend(token_and_woman_list)\n",
        "token_list.extend(token_and_artstyle_list)\n",
        "token_list.extend(token_and_other_list)\n",
        "\n",
        "\n",
        "for t in token_list:\n",
        "    print(t)\n",
        "#@markdown For every token in your list, the class word will be appended to that token and added to the list. \\\n",
        "#@markdown Ex. If you have `'wow, owo, sks'` in your list, and select `'person'` class, then the list would become:\n",
        "#@markdown * wow\n",
        "#@markdown * owo\n",
        "#@markdown * sks\n",
        "#@markdown * wow person\n",
        "#@markdown * owo person\n",
        "#@markdown * sks person\n",
        "# add class word variant to list?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mglPWeABMk3v"
      },
      "outputs": [],
      "source": [
        "#@title 5. Generate!\n",
        "\n",
        "\n",
        "seed = -1 #@param {type:\"number\"}\n",
        "steps = 18 #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "preview_grid_scale = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "\n",
        "if seed > 9223372036854775807:\n",
        "  print(\"seed value too big.\")\n",
        "else:\n",
        "  #print(int(steps))\n",
        "  #print(preview_grid_size/100)\n",
        "  generate_grid(seed, steps, preview_grid_scale)\n",
        "\n",
        "  print(\"grids saved in 'output' directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jstCM9gioXkt"
      },
      "outputs": [],
      "source": [
        "#@title 6. Display Images Results\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import glob\n",
        "\n",
        "print(\"These images will be half size. To get full-size images, set scale to 1.0 or download directly from the folder\")\n",
        "scale = 0.5\n",
        "\n",
        "#get all images in the output folder \n",
        " \n",
        "img_list = glob.glob(f'{OUTPUT_DIR}/*.jpg')\n",
        "\n",
        "for img in img_list:\n",
        "  print(\"\\n\\n\" + img)  \n",
        "  image = Image.open(f'{img}')\n",
        "  display(image.resize(( int(image.width * scale), int(image.height * scale))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T4pFHQD54BGL"
      },
      "outputs": [],
      "source": [
        "#@title 6. Save All Grid Images To Zip Archive\n",
        "# for downloading or moving to your google drive\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "ARCHIVE_NAME = \"\" #@param {type:\"string\"}\n",
        "#@markdown leave empty for default name. \n",
        "\n",
        "if len(ARCHIVE_NAME)==0:\n",
        "  ARCHIVE_NAME = 'token_grids'\n",
        "\n",
        "archive_path = shutil.make_archive(ARCHIVE_NAME, 'zip', OUTPUT_DIR)\n",
        "\n",
        "# Copy to google drive?\n",
        "COPY_TO_GOOGLE_DRIVE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if COPY_TO_GOOGLE_DRIVE:  \n",
        "  google_drive_dir = '/content/drive'\n",
        "\n",
        "  if path.exists(google_drive_dir)==False: \n",
        "    drive.mount(google_drive_dir)\n",
        "  else: \n",
        "    print(f'Google Drive already mounted at {google_drive_dir}')\n",
        "    # drive.mount('/content/drive')\n",
        "\n",
        "  shutil.copy(archive_path, google_drive_dir + '/MyDrive')\n",
        "  print(\"Archive copied to \"+ google_drive_dir + '/MyDrive/'+ ARCHIVE_NAME + '.zip') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N3GKXWWQPwwj"
      },
      "outputs": [],
      "source": [
        "#@title Delete images from dir /content/output\n",
        "import os, shutil\n",
        "\n",
        "dir = \"/content/output\"\n",
        "\n",
        "#!rm -rf \"$dir\"\n",
        "\n",
        "for filename in os.listdir(dir):\n",
        "    file_path = os.path.join(dir, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "        \n",
        "print(\"you may need to refresh the file manager view if the files is still visible after deleting.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
